\documentclass[letterpaper,12pt]{article}

\usepackage{threeparttable}
\usepackage{geometry}
\geometry{letterpaper,tmargin=1in,bmargin=1in,lmargin=1.25in,rmargin=1.25in}
\usepackage[format=hang,font=normalsize,labelfont=bf]{caption}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{multirow}
\usepackage{array}
\usepackage{delarray}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{lscape}
\usepackage{natbib}
\usepackage{setspace}
\usepackage{float,color}
\usepackage[pdftex]{graphicx}
\usepackage{pdfsync}
\usepackage{verbatim}
\usepackage{placeins}
\usepackage{geometry}
\usepackage{pdflscape}
\synctex=1
\usepackage{hyperref}
\hypersetup{colorlinks,linkcolor=red,urlcolor=blue,citecolor=red}
\usepackage{bm}


\theoremstyle{definition}
\newtheorem{theorem}{Theorem}
\newtheorem{acknowledgement}[theorem]{Acknowledgement}
\newtheorem{algorithm}[theorem]{Algorithm}
\newtheorem{axiom}[theorem]{Axiom}
\newtheorem{case}[theorem]{Case}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{conclusion}[theorem]{Conclusion}
\newtheorem{condition}[theorem]{Condition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{criterion}[theorem]{Criterion}
\newtheorem{definition}{Definition} % Number definitions on their own
\newtheorem{derivation}{Derivation} % Number derivations on their own
\newtheorem{example}[theorem]{Example}
\newtheorem{exercise}[theorem]{Exercise}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{notation}[theorem]{Notation}
\newtheorem{problem}[theorem]{Problem}
\newtheorem{proposition}{Proposition} % Number propositions on their own
\newtheorem{remark}[theorem]{Remark}
\newtheorem{solution}[theorem]{Solution}
\newtheorem{summary}[theorem]{Summary}
\bibliographystyle{aer}
\newcommand\ve{\varepsilon}
\renewcommand\theenumi{\roman{enumi}}
\newcommand\norm[1]{\left\lVert#1\right\rVert}

\begin{document}

\title{Math 344 Homework 2.4}
\author{Chris Rytting}
\maketitle
\subsection*{2.21}
We observe that $D$ is given by:
\[
    \begin{bmatrix}
        0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 2 & 0 & 0 \\
        0 & 0 & 0 & 3 & 0 \\
        0 & 0 & 0 & 0 & 4 \\
        0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
\]

While
\begin{align*}
    D^2
    &= 
    \begin{bmatrix}
        0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 2 & 0 & 0 \\
        0 & 0 & 0 & 3 & 0 \\
        0 & 0 & 0 & 0 & 4 \\
        0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
    \begin{bmatrix}
        0 & 1 & 0 & 0 & 0 \\
        0 & 0 & 2 & 0 & 0 \\
        0 & 0 & 0 & 3 & 0 \\
        0 & 0 & 0 & 0 & 4 \\
        0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
    = 
    \begin{bmatrix}
        0 & 0 & 2 & 0 & 0 \\
        0 & 0 & 0 & 6 & 0 \\
        0 & 0 & 0 & 0 & 12 \\
        0 & 0 & 0 & 0 & 0 \\
        0 & 0 & 0 & 0 & 0 
    \end{bmatrix}
\end{align*}
Which is the desired result.


\subsection*{2.22}
We know that
\begin{align*}
    \text{tr} (AB) = \sum^{n}_{i=1} a_{1i} b_{i1} +\sum^{n}_{i=1} a_{2i} b_{i2} +\dots +\sum^{n}_{i=1} a_{ni} b_{in}= \sum^{n}_{k=1} \Big( \sum^{n}_{i=1} a_{ki} b_{ik} \Big)\\
    \text{tr} (BA) = \sum^{n}_{i=1} b_{1i} a_{i1} +\sum^{n}_{i=1} b_{2i} a_{i2} +\dots +\sum^{n}_{i=1} b_{ni} a_{in} = \sum^{n}_{k=1} \Big( \sum^{n}_{i=1} b_{ki} a_{ik} \Big)\\
\end{align*}
as each of these individual summations yields an entry of the diagonal of $AB$ and $BA$, respectively. We know, however, that 
\begin{align*}
    \sum^{n}_{i=1} \Big( \sum^{n}_{k=1} a_{ik}b_{ki}\Big) =
    \sum^{n}_{i=1} \Big( \sum^{n}_{k=1} b_{ik}a_{ki}\Big)
\end{align*}
Therefore, we know that 
\begin{align*}
    \text{tr} (AB) = \sum^{n}_{i=1} a_{1i} b_{i1} +\sum^{n}_{i=1} a_{2i} b_{i2} +\dots +\sum^{n}_{i=1} a_{ni} b_{in} \\= \sum^{n}_{k=1}\Big( \sum^{n}_{i=1} a_{ki} b_{ik} \Big) = \sum^{n}_{k=1} \Big( \sum^{n}_{i=1} b_{ki} a_{ik} \Big)
    \\= \sum^{n}_{i=1} b_{1i} a_{i1} +\sum^{n}_{i=1} b_{2i} a_{i2} +\dots +\sum^{n}_{i=1} b_{ni} a_{in} = \text{tr} (AB)
\end{align*}
\subsection*{2.22 (ii)}
We know that 
\begin{align*}
    A&=P^{-1}BP\\
    \text{tr} (A) &=\text{tr} ( P^{-1}BP)\\
    \text{tr} (A) &=\text{tr} ( (P^{-1}B)P)\\
    \text{And by part (i),} \\
    \text{tr} (A) &=\text{tr} ( P(P^{-1}B))\\
    \text{tr} (A) &=\text{tr} ( PP^{-1}B)\\
    \text{tr} (A) &=\text{tr} ( IB)\\
    \text{tr} (A) &=\text{tr} ( B)\\
\end{align*}
Which is the desired result.

\subsection*{2.22 (iii)}

We know that
\begin{align*}
\text{tr} (AB) = \sum^{n}_{i=1} a_{1i} b_{i1} +\sum^{n}_{i=1} a_{2i} b_{i2} +\dots +\sum^{n}_{i=1} a_{ni} b_{in}= \sum^{n}_{k=1} \Big( \sum^{n}_{i=1} a_{ki} b_{ik} \Big)\\
\end{align*}
where the rows of $A$ are multiplied by the columns of $B$. If we transpose $B$, though, we will be multiplying the rows of $A$ by the rows of $B$, yielding

\begin{align*}
\text{tr} (AB^T) = \sum^{n}_{i=1} a_{1i} b_{1i} +\sum^{n}_{i=1} a_{2i} b_{2i} +\dots +\sum^{n}_{i=1} a_{ni} b_{ni}= \sum^{n}_{k=1} \Big( \sum^{n}_{i=1} a_{ki} b_{ki} \Big)\\
\end{align*}
which is equivalent to showing the desired result, just with a $k$ index instead of a $j$ index.

\subsection*{2.23}
We know that $A = P^{-1}BP$, and that 

\begin{align*}
p(A) &= a_nA^n + a_{n-1}A^{n-1} +\dots+ a_1A^1 + a_0A^0\\
p(A) &= a_n(P^{-1}BP)^n + a_{n-1}(P^{-1}BP)^{n-1} +\dots+ a_1(P^{-1}BP)^1 + a_0(P^{-1}BP)^0\\
\end{align*}
Notice, however, that 
\begin{align*}
A^n &=(P^{-1}BP)^n 
\\&= (P^{-1}BP)(P^{-1}BP)\dots(P^{-1}BP)
\\&= (P^{-1}BPP^{-1}BP\dots P^{-1}BP) 
\\&= (P^{-1}BIBI\dots IBP) 
\\&= (P^{-1}B^nP)
\end{align*}
Thus we have
\begin{align*}
p(A) &= a_nP^{-1}(B)^nP + a_{n-1}P^{-1}(B)^{n-1}P +\dots+ a_1P^{-1}(B)^1P + a_0P^{-1}(B)^0P
\\&= P^{-1}(a_n(B)^n + a_{n-1}(B)^{n-1} +\dots+ a_1(B)^1 + a_0(B)^0)P 
\\&= P^{-1}p(B)P 
\end{align*}

\subsection*{2.24}
Reflexivity:
Note that
\[A = I^{-1}AI = A \]
So $A$ is similar to itself.

Symmetrical:
Let $A$ be similar to $B$, then
\begin{align*}
    A = P^{-1}BP
    \implies B = PBP^{-1}
\end{align*}
So $B$ is also similar to $A$.

Transitive:
Let $A$ be similar to $B$ and let $B$ be similar to $C$, then 
\begin{align*}
\\A &= P^{-1}BP
\\B &= Q^{-1}CQ
\\\implies A &= P^{-1}Q^{-1}CQP
\\\implies A &= S^{-1}CS \quad \text{ where $S = QP$} 
\end{align*}
Now, since we know that the product of two nonsingular matrices is nonsingular, we have that $A$ is similar to $C$.
\\
\\
The set of all $1 \times 1$ matrices

\subsection*{2.25}
Let $A,B$ be similar matrices, with $A$ being invertible. Then we have that 
\[ A = P^{-1}BP \quad B = PAP^{-1}\]
Now, since we know that $P$ is invertible by the definition of similar matrices, and that $A$ is invertible by assumption, we know that $B$ is invertible as it is the product of three nonsingular matrices, which we know results in a nonsingular matrix from linear algebra.

\subsection*{2.26}
Consider two similar matrices $A,B$. Let \[ S = \{b_1,b_2,\dots, b_n\}\]
be a basis be a basis for $\mathscr{N} (B)$. Therfore, 
\begin{align*}
    b_i \in S, Bb = 0 
    \\\implies P^{-1}APb = 0 \implies APb = P0 \implies APb = 0. \implies 
    \\ \{Pb_1,Pb_2,\dots, Pb_n\}
\end{align*}
Which is linearly independent. Now let $x \in \mathscr{N} (A)$. So $PBP^{-1}x = 0 = Ax \implies BP^{-1} = 0.$ So $P^{-1} x\in \mathscr{N} (B)$. So $P^{-1}x \in \mathscr{N} (B) \implies P^{-1}x = a_1b_1 + a_2b_2 + \dots + a_nb_n$
because of our assumption about $\mathscr{N} (B)$. 
\begin{align*}
    \implies x = a_1Pb_1 +a_2Pb_2 +\dots + a_nPb_n \\\implies  \{Pb_1,Pb_2,\dots, Pb_n\} \text{ spans } \mathscr{N} (A) \text{ and forms a basis for } \mathscr{N} (A).
\end{align*}
So we have that $\text{dim} (\mathscr{N} B) = \text{dim} (\mathscr{N} A) = \text{ Nullity } (A) = \text{ Nullity } (B)$. By rank-nullity, we have 
\[ \text{Rank } (A) = \mathscr{N} (A) - \text{ nullity } (A) = \mathscr{N} (B) - \text{ nullity } (B) = \text{ rank } (B)\]






\end{document}
